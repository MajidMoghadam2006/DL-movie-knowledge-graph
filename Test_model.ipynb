{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this notebook to evaluate the pre-trained model performance\n",
    "# Majid Moghadam (Student ID: 1708800)\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ID    UTTERANCE    CORE RELATIONS\n",
    "trainFile = pd.read_csv('dataset/hw1_train.csv')\n",
    "# ID    UTTERANCE\n",
    "testFile = pd.read_csv('dataset/hw1_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "\n",
    "# input features\n",
    "X = list(trainFile['UTTERANCE'])\n",
    "\n",
    "unique_relations = []\n",
    "for relation_str in trainFile['CORE RELATIONS']:\n",
    "    relations = relation_str.split(' ')\n",
    "    for relation in relations:\n",
    "        if relation not in unique_relations:\n",
    "            unique_relations.append(relation)\n",
    "\n",
    "unique_nodes = []\n",
    "for path in unique_relations:\n",
    "    nodes = path.split('.')\n",
    "    for node in nodes:\n",
    "        if node not in unique_nodes:\n",
    "            unique_nodes.append(node)\n",
    "\n",
    "# add label columns to dataframe\n",
    "for relation in unique_relations:\n",
    "    trainFile[relation] = 0\n",
    "\n",
    "# fill out label columns\n",
    "for idx, relation_str in enumerate(trainFile['CORE RELATIONS']):\n",
    "    relations = relation_str.split(' ')\n",
    "    for relation in relations:\n",
    "        trainFile.loc[idx,relation] = 1\n",
    "\n",
    "#separate label columns\n",
    "labels = trainFile[unique_relations]\n",
    "\n",
    "# target values\n",
    "y = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(hyperParams):\n",
    "    \n",
    "    hidden_layers = hyperParams['hidden_layers']\n",
    "    activation = hyperParams['activation']\n",
    "    dropout = hyperParams['dropout']\n",
    "    output_activation = hyperParams['output_activation']\n",
    "    loss = hyperParams['loss']\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layers[0], input_shape=(5000,), activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(len(hidden_layers)-1):\n",
    "        model.add(Dense(hidden_layers[i], activation=activation))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(46, activation=output_activation))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['accuracy', f1_score])\n",
    "    # categorical_crossentropy, binary_crossentropy f1_loss->(for tensorflow 1.14)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data and convert to vector\n",
    "\n",
    "# training data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_matrix(X)\n",
    "\n",
    "# test data\n",
    "X_t = list(testFile['UTTERANCE'])\n",
    "X_pred = tokenizer.texts_to_matrix(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model:\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model.h5\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3338/3338 [==============================] - 1s 230us/step\n",
      "Validation F1 score:  0.9993001476171275\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, y, verbose=1)\n",
    "\n",
    "print('Validation F1 score: ', scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
