{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPool2D, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
    "from tensorflow.keras.layers import MaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID    UTTERANCE    CORE RELATIONS\n",
    "trainFile = pd.read_csv('dataset/hw1_train.csv')\n",
    "# ID    UTTERANCE\n",
    "testFile = pd.read_csv('dataset/hw1_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "\n",
    "# input features\n",
    "X = list(trainFile['UTTERANCE'])\n",
    "\n",
    "unique_relations = []\n",
    "for relation_str in trainFile['CORE RELATIONS']:\n",
    "    relations = relation_str.split(' ')\n",
    "    for relation in relations:\n",
    "        if relation not in unique_relations:\n",
    "            unique_relations.append(relation)\n",
    "\n",
    "unique_nodes = []\n",
    "for path in unique_relations:\n",
    "    nodes = path.split('.')\n",
    "    for node in nodes:\n",
    "        if node not in unique_nodes:\n",
    "            unique_nodes.append(node)\n",
    "\n",
    "# add label columns to dataframe\n",
    "for relation in unique_relations:\n",
    "    trainFile[relation] = 0\n",
    "\n",
    "# fill out label columns\n",
    "for idx, relation_str in enumerate(trainFile['CORE RELATIONS']):\n",
    "    relations = relation_str.split(' ')\n",
    "    for relation in relations:\n",
    "        trainFile.loc[idx,relation] = 1\n",
    "\n",
    "#separate label columns\n",
    "labels = trainFile[unique_relations]\n",
    "\n",
    "# target values\n",
    "y = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5000 words because the training set has almost 2500 unique words\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hidden_layers=[512, 512], activations=['relu', 'relu'], dropouts=[0.3, 0.3], \n",
    "                 output_activation='sigmoid', loss='binary_crossentropy'):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layers[0], input_shape=(5000,), activation=activations[0]))\n",
    "    model.add(Dropout(dropouts[0]))\n",
    "    for i in range(len(hidden_layers)-1):\n",
    "        model.add(Dense(hidden_layers[i], activation=activations[i]))\n",
    "        model.add(Dropout(dropouts[i]))\n",
    "    model.add(Dense(46, activation=output_activation))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['accuracy', f1_score])\n",
    "    # categorical_crossentropy, binary_crossentropy f1_loss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model_fit(X, y):\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    scores=[]\n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        model = create_model()\n",
    "        model.fit(X[train_idx], y[train_idx], batch_size=32, epochs=25, verbose=0)\n",
    "        score = model.evaluate(X[test_idx], y[test_idx], verbose=0)\n",
    "        scores.append(score[2]*100) # f_score\n",
    "        print('fold ', len(scores), '  score: ', scores[-1])\n",
    "        del model\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  1   score:  85.6295645236969\n",
      "fold  2   score:  80.89064955711365\n",
      "fold  3   score:  85.08695363998413\n",
      "fold  4   score:  84.84514355659485\n",
      "fold  5   score:  84.48495864868164\n",
      "fold  6   score:  85.81226468086243\n",
      "fold  7   score:  83.19141268730164\n",
      "fold  8   score:  84.53482985496521\n",
      "fold  9   score:  79.93490099906921\n",
      "fold  10   score:  84.38608646392822\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e1d62551c5b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcvscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "cvscores = cv_model_fit(X, y)\n",
    "print([np.mean(cvscores).round(2), np.std(cvscores).round(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3338 samples\n",
      "Epoch 1/25\n",
      "3338/3338 [==============================] - 1s 221us/sample - loss: 0.1646 - accuracy: 0.9654 - f1_score: 0.0024\n",
      "Epoch 2/25\n",
      "3338/3338 [==============================] - 0s 82us/sample - loss: 0.0621 - accuracy: 0.9807 - f1_score: 0.3492\n",
      "Epoch 3/25\n",
      "3338/3338 [==============================] - 0s 82us/sample - loss: 0.0349 - accuracy: 0.9892 - f1_score: 0.7361\n",
      "Epoch 4/25\n",
      "3338/3338 [==============================] - 0s 80us/sample - loss: 0.0230 - accuracy: 0.9929 - f1_score: 0.8398\n",
      "Epoch 5/25\n",
      "3338/3338 [==============================] - 0s 84us/sample - loss: 0.0159 - accuracy: 0.9952 - f1_score: 0.8971\n",
      "Epoch 6/25\n",
      "3338/3338 [==============================] - 0s 81us/sample - loss: 0.0121 - accuracy: 0.9963 - f1_score: 0.9218\n",
      "Epoch 7/25\n",
      "3338/3338 [==============================] - 0s 81us/sample - loss: 0.0091 - accuracy: 0.9972 - f1_score: 0.9397\n",
      "Epoch 8/25\n",
      "3338/3338 [==============================] - 0s 82us/sample - loss: 0.0071 - accuracy: 0.9979 - f1_score: 0.9565\n",
      "Epoch 9/25\n",
      "3338/3338 [==============================] - 0s 79us/sample - loss: 0.0057 - accuracy: 0.9982 - f1_score: 0.9624\n",
      "Epoch 10/25\n",
      "3338/3338 [==============================] - 0s 83us/sample - loss: 0.0044 - accuracy: 0.9987 - f1_score: 0.9736\n",
      "Epoch 11/25\n",
      "3338/3338 [==============================] - 0s 81us/sample - loss: 0.0040 - accuracy: 0.9990 - f1_score: 0.9787\n",
      "Epoch 12/25\n",
      "3338/3338 [==============================] - 0s 80us/sample - loss: 0.0033 - accuracy: 0.9991 - f1_score: 0.9811\n",
      "Epoch 13/25\n",
      "3338/3338 [==============================] - 0s 79us/sample - loss: 0.0026 - accuracy: 0.9993 - f1_score: 0.9858\n",
      "Epoch 14/25\n",
      "3338/3338 [==============================] - 0s 79us/sample - loss: 0.0025 - accuracy: 0.9992 - f1_score: 0.9842\n",
      "Epoch 15/25\n",
      "3338/3338 [==============================] - 0s 79us/sample - loss: 0.0020 - accuracy: 0.9994 - f1_score: 0.9876\n",
      "Epoch 16/25\n",
      "3338/3338 [==============================] - 0s 82us/sample - loss: 0.0017 - accuracy: 0.9995 - f1_score: 0.9907\n",
      "Epoch 17/25\n",
      "3338/3338 [==============================] - 0s 81us/sample - loss: 0.0019 - accuracy: 0.9995 - f1_score: 0.9893\n",
      "Epoch 18/25\n",
      "3338/3338 [==============================] - 0s 92us/sample - loss: 0.0014 - accuracy: 0.9996 - f1_score: 0.9913\n",
      "Epoch 19/25\n",
      "3338/3338 [==============================] - 0s 89us/sample - loss: 0.0015 - accuracy: 0.9996 - f1_score: 0.9915\n",
      "Epoch 20/25\n",
      "3338/3338 [==============================] - 0s 84us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_score: 0.9945\n",
      "Epoch 21/25\n",
      "3338/3338 [==============================] - 0s 80us/sample - loss: 0.0011 - accuracy: 0.9997 - f1_score: 0.9935\n",
      "Epoch 22/25\n",
      "3338/3338 [==============================] - 0s 80us/sample - loss: 8.4193e-04 - accuracy: 0.9998 - f1_score: 0.9957\n",
      "Epoch 23/25\n",
      "3338/3338 [==============================] - 0s 80us/sample - loss: 0.0010 - accuracy: 0.9997 - f1_score: 0.9948\n",
      "Epoch 24/25\n",
      "3338/3338 [==============================] - 0s 80us/sample - loss: 7.8300e-04 - accuracy: 0.9998 - f1_score: 0.9966\n",
      "Epoch 25/25\n",
      "3338/3338 [==============================] - 0s 80us/sample - loss: 8.3062e-04 - accuracy: 0.9998 - f1_score: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff384548f28>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build last model from full data\n",
    "model = create_model()\n",
    "model.fit(X, y, batch_size=32, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = list(testFile['UTTERANCE'])\n",
    "X_pred = tokenizer.texts_to_matrix(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for y in y_pred:\n",
    "    temp = ''\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.5:\n",
    "            temp += ' ' + unique_relations[i]\n",
    "    if len(temp) < 1: temp = unique_relations[np.argmax(y)]\n",
    "    # if len(temp)>= 2: print(temp)\n",
    "    predictions.append(temp.strip())\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CORE RELATIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID        CORE RELATIONS\n",
       "0   0  movie.starring.actor\n",
       "1   1  movie.starring.actor\n",
       "2   2  movie.starring.actor\n",
       "3   3  movie.starring.actor\n",
       "4   4  movie.starring.actor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissionFile = pd.DataFrame({\n",
    "    'ID': [i for i in range(len(predictions))],\n",
    "    'CORE RELATIONS': predictions})\n",
    "path_to_save = os.path.abspath(os.getcwd()) + '/predictions/'\n",
    "submissionFile.to_csv('predictions/prediction12.csv', index = None)\n",
    "submissionFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
